"""Incorporate ETH Zurich's BIWI (EWAP) dataset into simple gridworld."""

import os
from pathlib import Path
from matplotlib.image import imread
import numpy as np

from .simple_gw import SimpleGridworld

# Grid constants
OBSTACLE = 2
GOAL = 6
PERSON = 9


class EwapDataset:
    """
    Contains all relevant information for EWAP dataset.
    """

    def __init__(
            self,
            dataset_root='datasets/ewap_dataset',
            sequence='seq_hotel'
    ):
        dataset_path = Path(os.path.abspath(__file__)).parents[0]
        self.sequence_path = dataset_path / dataset_root / sequence

        # get obstacle map
        obs_map_path = self.sequence_path / 'hmap.png'
        self.obstacle_map = imread(str(obs_map_path.resolve()))
        self.obstacle_map *= OBSTACLE

        # get pedestrian position and velocity data (obsmat.txt)
        self.pedestrian_data = np.loadtxt(self.sequence_path / 'obsmat.txt')

        # get shift and scale amount for this sequence
        self.pos_shift = np.loadtxt(self.sequence_path / 'shift.txt')
        self.scale_factor = np.loadtxt(self.sequence_path / 'scale.txt')

        self.frame_id = 0
        self.processed_data = self.process_data()

    def scale(self, raw_data):
        scaled_data = raw_data.copy()
        scaled_data[:, 2:] *= self.scale_factor

        return scaled_data

    def shift(self, scaled_ped_data):
        shifted_ped_data = scaled_ped_data.copy()
        shifted_ped_data[:, 2] = shifted_ped_data[:, 2] - self.pos_shift[0]
        shifted_ped_data[:, 4] = shifted_ped_data[:, 4] - self.pos_shift[1]

        return shifted_ped_data

    def discretize(self, scaled_shifted_data):
        discrete_data = np.round(scaled_shifted_data).astype(np.int64)

        return discrete_data

    def normalize_frames(self, unnormalied_data):
        """
        Normalizers the data frames, so first frame is integer 0.
        """
        normalized_data = unnormalied_data.copy()
        normalized_data[:, 0] -= np.min(normalized_data[:, 0])

        return normalized_data

    def process_data(self):
        """
        scales, shifts, and discretizes input data according to parameters
        generated by map2world.py script. normalizes frame numbers.
        """

        scaled_data = self.scale(self.pedestrian_data)
        shifted_data = self.shift(scaled_data)
        discrete_data = self.discretize(shifted_data)

        # normalize frames
        processed_data = self.normalize_frames(discrete_data)

        return processed_data

    def pad_dataset(self, pad_amount):
        """
        Pad dataset with obstacle pixels to ensure 2*vision_radius+1 squares
        are possible for feature extractor.
        """
        self.obstacle_map = np.pad(
            self.obstacle_map,
            pad_amount + 1,  # for when agent runs into obstacle
            mode='constant',
            constant_values=OBSTACLE
        )

        # shift dataset to accomodate padding
        self.processed_data[:, 2] += pad_amount
        self.processed_data[:, 4] += pad_amount


class EwapGridworld(SimpleGridworld):
    """
    Env that incorporates ETHZ BIWI (EWAP) dataset.
    make sure the correct directory sturcture exists in order to run, i.e.

    /envs/datasets/ewap_dataset/seq_eth
    /envs/datasets/ewap_dataset/seq_hotel

    folders exist. Additionally, run script map2world.py for both sequences,
    instruction found in the script at /envs/datasets/ewap_dataset/map2world.py
    """

    def __init__(
            self,
            sequence='seq_hotel',
            dataset_root='datasets/ewap_dataset',
            person_thickness=4,
            vision_radius=4,
    ):
        """
        Initialize EWAP gridworld. Make sure all files in the correct
        directories as specified above!

        :param sequence: Sequence to base world on. example: 'seq_hotel'
        :param dataset_root: path to root of dataset directory.
        :param person_thickness: The dimensions of the nxn boxes that will
        represent people.
        """

        self.dataset = EwapDataset(
            sequence=sequence,
            dataset_root=dataset_root
        )

        self.vision_radius = vision_radius
        self.dataset.pad_dataset(vision_radius)

        self.person_thickness = person_thickness

        obstacle_array = np.where(self.dataset.obstacle_map == OBSTACLE)
        obstacle_array = np.array(obstacle_array).T

        super().__init__(
            self.dataset.obstacle_map.shape,
            obstacle_array,
            (vision_radius + 1, vision_radius + 1)
        )

        # seperate for people position incase we want to do processing.
        self.person_map = self.grid.copy()
        self.person_map.fill(0)

    def thicken(self, grid, target_thickness):
        """
        thicken pixel by specified target_thickness parameter in supplied grid.

        :param target_thickness: thickness amount.
        :param grid: grid in which pixels reside.
        """

        filt = np.ones(target_thickness)

        def thicken_along_axis(grid):
            return np.convolve(grid, filt, mode='same')

        thick = np.apply_along_axis(thicken_along_axis, axis=0, arr=grid)
        thick = np.apply_along_axis(thicken_along_axis, axis=1, arr=thick)

        return thick

    def populate_person_map(self, frame_num):
        """Populates the person map based on input frame_num, which is the
        frame id of EWAP database's footage.

        :param frame_num: frame to get positions from.
        """
        # clear person map
        self.person_map.fill(0)

        # Get data for current frame of simulation.
        frame_pedestrians = self.dataset.processed_data[
            self.dataset.processed_data[:, 0] == frame_num
        ]

        self.person_map[frame_pedestrians[:, 2],
                        frame_pedestrians[:, 4]] = PERSON
        self.person_map = self.thicken(self.person_map, self.person_thickness)

    def reset(self):
        """
        reset gridworld to initial positon, with all trajectories starting
        again at first frame.
        """

        super().reset()

        assert self.step_number == 0, 'non-zero step number after reset!'

        # get people's positions at start of sequence.
        self.populate_person_map(self.step_number)

        self.grid += self.person_map

        return self.state_extractor().astype('float32')

    def reward_function(self, state, action, next_state):
        reward = super().reward_function(state, action, next_state)

        if self.grid[tuple(self.player_pos)] == PERSON:
            reward += -10.0

        return reward

    def state_extractor(self):
        """
        Extract state for CURRENT internal state of gridworld.
        """

        state = self.grid[
            self.player_pos[0] - self.vision_radius: self.player_pos[0] + self.vision_radius + 1,
            self.player_pos[1] - self.vision_radius: self.player_pos[1] + self.vision_radius + 1,
        ]

        try:
            assert state.shape == (
                2 * self.vision_radius + 1, 2 * self.vision_radius + 1)
        except AssertionError:
            breakpoint()

        return state.flatten()

    def step(self, action):
        """
        Advance the gridworld player based on action.
        'done' is set when environment reaches goal, hits obstacle, or exceeds
        max step number, which is heuristically set to length*height of
        gridworld.

        :param action: Action peformed by player.
        :return (next_state, reward, done, False)
        """
        assert self.action_space.contains(action), "Invalid action!"

        action_vector = self.action_dict[action]

        next_pos = self.player_pos + action_vector

        # constrain agent position to the bounds of gridworld.
        next_pos = next_pos.clip(
            [0, 0],
            [self.grid.shape[0] - 1, self.grid.shape[1] - 1]
        )

        # extract current and next state
        state = self.state_extractor().astype('float32')

        self.player_pos = next_pos

        next_state = self.state_extractor().astype('float32')

        self.step_number += 1

        # reward function r(s_t, a_t, s_t+1)
        reward = self.reward_function(state, action, next_state)

        goal_reached = (self.player_pos == self.goal_pos).all()
        obstacle_hit = (self.grid[tuple(self.player_pos)] == OBSTACLE)
        person_hit = (self.grid[tuple(self.player_pos)] == PERSON)
        max_steps_elapsed = self.step_number > self.grid.size

        done = goal_reached or obstacle_hit or max_steps_elapsed or person_hit

        return next_state, reward, done, False
